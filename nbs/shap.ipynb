{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model and get SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_plots(data, fold_type, explainer_type, model_type, cols=None):\n",
    "    model = data['model']\n",
    "    df_train = data['df_train']\n",
    "    df_train_target = data['df_train_target']\n",
    "    features = data['features']\n",
    "    test = data['test']\n",
    "    train_os = data['train_os']\n",
    "    mask = data['mask']\n",
    "    \n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([0,1,2,3]), 'Species'] = 0\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([4,5,6,7,8]),'Species'] = 1\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([9,10,11,12]),'Species'] = 2\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([13,14,15,16]),'Species'] = 3\n",
    "\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([17,18,19,20,21,22]), 'Species'] = 0\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([23,24,25,26,27,28]),'Species'] = 1\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([29,30,31,32,33,34]),'Species'] = 2\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([35,36,37,38,39]),'Species'] = 3\n",
    "\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([0,1,2,3]),'Target'] = 0\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([13,14,15,16]),'Target'] = 0\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([4,5,6,7,8]),'Target'] = 0\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([9,10,11,12]),'Target'] = 0\n",
    "\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([17,18,19,20,21,22]),'Target'] = 1\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([23,24,25,26,27,28]),'Target'] = 1\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([29,30,31,32,33,34]),'Target'] = 1\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([35,36,37,38,39]),'Target'] = 1\n",
    "\n",
    "    print('Initalising SHAP...')\n",
    "    if explainer_type == 'TreeExplainer':\n",
    "        explainer = shap.TreeExplainer(model, data=train_os, model_output='probability')\n",
    "    elif explainer_type == 'Explainer':\n",
    "        explainer = shap.Explainer(model, train_os)\n",
    "\n",
    "    print('Computing SHAP values...')\n",
    "    try:\n",
    "        test = test.sample(5000, random_state=0)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    shap_vals = explainer.shap_values(test)\n",
    "\n",
    "    print('Generating plots...')\n",
    "\n",
    "    plt.figure(figsize=(12,15), dpi=300)\n",
    "    if model_type == 'Random Forests':\n",
    "        shap.summary_plot(shap_vals[1], test, show=False, plot_size=[12,15], max_display=len(test.columns), alpha=0.7, feature_names=cols)\n",
    "    else:\n",
    "        shap.summary_plot(shap_vals, test, show=False, plot_size=[12,15], max_display=len(test.columns), alpha=0.7, feature_names=cols)\n",
    "    #plt.title(f'SUMMARY PLOT - {model_type} - {fold_type}')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12,15), dpi=300)\n",
    "    shap.summary_plot(shap_vals, test, plot_type=\"bar\", show=False, plot_size=[12,15], max_display=len(test.columns), feature_names=cols)\n",
    "    #plt.title(f'BAR PLOT - {model_type} - {fold_type}')\n",
    "    plt.show()\n",
    "    #'''\n",
    "    for index, species in enumerate(['banfora', 'kisumu', 'ngoussu', 'vk7']):\n",
    "        data_species = df_train[features][(df_train_target['Species'] == index) & (~mask)]\n",
    "        indexes = list(set(data_species.index).intersection(test.index))\n",
    "        indexes = test.index.isin(indexes)\n",
    "        data_species = test.loc[indexes]\n",
    "\n",
    "\n",
    "        if model_type == 'Random Forests':\n",
    "            species_shap_vals = []\n",
    "            species_shap_vals.append(shap_vals[0][indexes])\n",
    "            species_shap_vals.append(shap_vals[1][indexes])\n",
    "        else:\n",
    "            species_shap_vals = shap_vals[indexes]\n",
    "        \n",
    "        plt.figure(figsize=(12,12), dpi=300)\n",
    "        if model_type == 'Random Forests':\n",
    "            shap.summary_plot(species_shap_vals[1], data_species, show=False, plot_size=[12,12], max_display=len(test.columns), alpha=0.7, feature_names=cols)\n",
    "        else:\n",
    "            shap.summary_plot(species_shap_vals, data_species, show=False, plot_size=[12,12], max_display=len(test.columns), alpha=0.7, feature_names=cols)\n",
    "        plt.title(f'SUMMARY PLOT - {model_type} - {fold_type} - {species}')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(12,12), dpi=300)\n",
    "        shap.summary_plot(species_shap_vals, data_species, plot_type=\"bar\", show=False, plot_size=[12,12], max_display=len(test.columns), feature_names=cols)\n",
    "        plt.title(f'BAR PLOT - {model_type} - {fold_type} - {species}')\n",
    "        plt.show()\n",
    "    #'''\n",
    "    \n",
    "def shap_scatter(data, fold_type, explainer_type, model_type):\n",
    "    model = data['model']\n",
    "    df_train = data['df_train']\n",
    "    df_train_target = data['df_train_target']\n",
    "    features = data['features']\n",
    "    test = data['test']\n",
    "    train_os = data['train_os']\n",
    "    mask = data['mask']\n",
    "    \n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([0,1,2,3]), 'Species'] = 0\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([4,5,6,7,8]),'Species'] = 1\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([9,10,11,12]),'Species'] = 2\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([13,14,15,16]),'Species'] = 3\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([0,1,2,3]),'Target'] = 1\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([13,14,15,16]),'Target'] = 0\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([4,5,6,7,8]),'Target'] = 0\n",
    "    df_train_target.loc[df_train_target['TrialID'].isin([9,10,11,12]),'Target'] = 1\n",
    "\n",
    "    print('Initalising SHAP...')\n",
    "    if explainer_type == 'TreeExplainer':\n",
    "        explainer = shap.TreeExplainer(model, data=train_os, model_output='probability')\n",
    "    elif explainer_type == 'Explainer':\n",
    "        explainer = shap.Explainer(model, train_os)\n",
    "\n",
    "    print('Computing SHAP values...')\n",
    "    test = test.sample(5000, random_state=0)\n",
    "\n",
    "    shap_vals = explainer(test)\n",
    "\n",
    "    print('Generating plots...')\n",
    "    return shap_vals, test\n",
    "\n",
    "\n",
    "def plot_heatmap(data, fold_type, explainer_type, model_type):\n",
    "    model = data['model']\n",
    "    df_train = data['df_train']\n",
    "    features = data['features']\n",
    "    test = data['test']\n",
    "    train_os = data['train_os']\n",
    "    mask = data['mask']\n",
    "\n",
    "    print('Initalising SHAP...')\n",
    "    if explainer_type == 'TreeExplainer':\n",
    "        explainer = shap.TreeExplainer(model, data=train_os, model_output='probability')\n",
    "    elif explainer_type == 'Explainer':\n",
    "        explainer = shap.Explainer(model, train_os)\n",
    "\n",
    "    print('Computing SHAP values...')\n",
    "    test = test.sample(5000, random_state=0)\n",
    "\n",
    "    #values = train_os.sample(5000, random_state=0)\n",
    "\n",
    "    shap_vals = explainer(test)\n",
    "\n",
    "    print('Generating plots...')\n",
    "    plt.figure(figsize=(12,15), dpi=300)\n",
    "    if model_type == 'Random Forests':\n",
    "        shap.plots.heatmap(shap_vals[1], instance_order=shap_vals[1].sum(1), show=False, max_display=20, plot_width=12)\n",
    "    else:\n",
    "        shap.plots.heatmap(shap_vals, instance_order=shap_vals.mean(1), show=False, max_display=20, plot_width=12)\n",
    "    plt.title(f'HEATMAP - {model_type} - {fold_type}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = 'E:/ITNS/olyset-vs-untreated/tests/13-run/'\n",
    "data_path = results_path + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 7\n",
    "shap_data = joblib.load(data_path+f'shap/xgboost_shap_dump_{index}.dat')\n",
    "shap_plots(shap_data, 'Best', 'TreeExplainer', 'XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction values\n",
    "\n",
    "index = 7\n",
    "data = joblib.load(data_path+f'shap/xgboost_shap_dump_{index}.dat')\n",
    "\n",
    "model = data['model']\n",
    "df_train = data['df_train']\n",
    "features = data['features']\n",
    "test = data['test']\n",
    "train_os = data['train_os']\n",
    "mask = data['mask']\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "test = test.sample(5000, random_state=0)\n",
    "\n",
    "shap_interaction = explainer.shap_interaction_values(test)\n",
    "\n",
    "# Get absolute mean of matrices\n",
    "mean_shap = np.abs(shap_interaction).mean(0)\n",
    "df = pd.DataFrame(mean_shap, index=test.columns, columns=test.columns)\n",
    "\n",
    "# times off diagonal by 2\n",
    "df.where(df.values == np.diagonal(df),df.values*2, inplace=True)\n",
    "\n",
    "# display \n",
    "fig = plt.figure(figsize=(45, 30), edgecolor='r', dpi=100)\n",
    "ax = fig.add_subplot()\n",
    "sns.heatmap(df.round(decimals=3), cmap='coolwarm', annot=True, fmt='.6g', cbar=False, ax=ax, )\n",
    "ax.tick_params(axis='x', labelsize=15, rotation=90)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.title(\"SHAP interaction values\", fontsize=60)\n",
    "plt.yticks(rotation=0) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "\n",
    "def get_track_prediction(y_true, scores, preds, groups):\n",
    "    unique_groups = groups.unique()\n",
    "    track_preds = []\n",
    "    track_true = []\n",
    "    avg_scores = []\n",
    "    for val in unique_groups:\n",
    "        indexes = np.where(groups == val)[0]\n",
    "        track_true.append(mode(y_true.values[indexes]))\n",
    "        avg_scores.append(np.mean(scores[indexes]))\n",
    "        if np.mean(preds[indexes]) >= 0.5: \n",
    "            track_preds.append(1)\n",
    "        else:\n",
    "            track_preds.append(0)\n",
    "\n",
    "    return track_true, track_preds, avg_scores\n",
    "\n",
    "labels = model.predict(test)\n",
    "scores = model.predict_proba(test)[:,1]\n",
    "\n",
    "track_true, track_preds, avg_scores = get_track_prediction(\n",
    "    test_targets['Target'], scores, labels, test_targets['TrackGroup'])\n",
    "\n",
    "print('segment bal acc: ', metrics.balanced_accuracy_score(test_targets['Target'], labels))\n",
    "print('segment roc auc: ', metrics.roc_auc_score(test_targets['Target'], scores))\n",
    "print('track  bal acc: ', metrics.balanced_accuracy_score(track_true, track_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 20))\n",
    "plot_importance(model, ax=ax, height=0.8, importance_type=\"cover\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 7\n",
    "shap_data = joblib.load(data_path+f'shap/xgboost_shap_dump_{index}.dat')\n",
    "shap_vals, test = shap_scatter(shap_data, 'Best', 'TreeExplainer', 'XGBoost')\n",
    "\n",
    "df_train = shap_data['df_train']\n",
    "features = shap_data['features']\n",
    "test_targets = shap_data['test_targets']\n",
    "targets = test_targets.loc[test.index.values]\n",
    "targets = targets['Target']\n",
    "\n",
    "train = df_train.iloc[~df_train.index.isin(shap_data['test'].index)]\n",
    "scaler = StandardScaler().fit(train[features])\n",
    "df = pd.DataFrame(scaler.inverse_transform(test), columns=features, index=test.index)\n",
    "\n",
    "path_to_save = 'E:/ITNS/olyset-vs-untreated/tests/13-run/shap/scatter/'\n",
    "\n",
    "shap_vals.data = df.values\n",
    "\n",
    "for feature in df.columns.values:\n",
    "    mask = targets.values == 1\n",
    "    plt.figure(figsize=(12,8), dpi=300)\n",
    "    shap.plots.scatter(shap_vals[:,feature], alpha=0.7, show=False)\n",
    "    plt.grid(True)\n",
    "    plt.title(f'SHAP Scatter plot of {feature}')\n",
    "    #plt.show()\n",
    "    #break\n",
    "    plt.savefig(path_to_save+f'{feature}.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "shap_data = joblib.load(data_path+f'shap/xgboost_shap_dump_{index}.dat')\n",
    "shap_vals, test = shap_scatter(shap_data, 'Best', 'TreeExplainer', 'XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = np.load(data_path + 'tracks_split.npy', allow_pickle=True)\n",
    "targets = np.load(data_path + 'trackTargets_split.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_tracks = tracks[test.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WATERFALL PLOT\n",
    "index = 2\n",
    "shap_data = joblib.load(data_path+f'shap/xgboost_shap_dump_{index}.dat')\n",
    "shap_vals, test = shap_scatter(shap_data, 'Best', 'TreeExplainer', 'XGBoost')\n",
    "\n",
    "selected_tracks = tracks[test.index.values]\n",
    "selected_targets = targets[test.index.values]\n",
    "\n",
    "path_to_save = 'E:/IR_VS_IS/tuned model/xgboost-mutual/shap/waterfall-plots/'\n",
    "\n",
    "for index, track in enumerate(selected_tracks):\n",
    "    target = selected_targets[index]\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 15))\n",
    "    \n",
    "    plt.sca(axs[0])\n",
    "    shap.plots.waterfall(\n",
    "        shap_vals[index], show=False, \n",
    "        max_display=15\n",
    "    )\n",
    "    axs[0].set_title('SHAP Waterfall Plot')\n",
    "\n",
    "    axs[1].plot(track[:, 0], track[:, 1])\n",
    "    axs[1].set_title(f'Track Index {index} | Target {target}')\n",
    "\n",
    "    plt.savefig(path_to_save+f'track-{index}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "30f568716b9af256ac498dfb314c1a98595c9f57e2e62c0bc97adba654735ca0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
